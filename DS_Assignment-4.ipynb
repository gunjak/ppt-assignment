{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Q1: What is the General Linear Model?\n",
        "\n",
        "Sol 1: General Linear Modelis a statistical framework.The purpose of the GLM is to examine and understand the relationships\n",
        "between variables by estimating the parameters of the model. It allows us to assess the impact of independent variables on\n",
        "the dependent variable and make predictions .It draws inferences about the population based on the sample data."
      ],
      "metadata": {
        "id": "WiR7W1ieReT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q2: Explain the assumptions of the General Linear Model.\n",
        "\n",
        "Sol 2: The key assumptions of the General Linear Model are:\n",
        "1. Linear relationship: There exists a linear relationship between the independent variable, x, and the dependent variable, y.\n",
        "2. Independence: The residuals are independent. In particular, there is no correlation between consecutive residuals in time series data.\n",
        "3. Homoscedasticity: The residuals have constant variance at every level of x.\n",
        "4. Normality: The residuals of the model are normally distributed.\n"
      ],
      "metadata": {
        "id": "oInD_WQgWP32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3: How do you interpret the coefficients in the GLM?\n",
        "\n",
        "Sol 3:The following we can interpret the coefficients in the GLM:\n",
        "1. Coefficient Sign:\n",
        "The sign (+ or -) of the coefficient indicates the direction of the relationship between the independent variable and\n",
        "the dependent variable. A positive coefficient indicates a positive relationship. Conversely, a negative coefficient\n",
        "indicates a negative relationship.\n",
        "2. Magnitude:\n",
        "The magnitude of the coefficient reflects the size of the effect that the independent variable has on the dependent\n",
        "variable, all else being equal. Larger coefficient values indicate a stronger influence of the independent variable\n",
        "on the dependent variable.\n",
        "3. Statistical Significance:\n",
        "The statistical significance of a coefficient is determined by its p-value. A low p-value suggests that the coefficient\n",
        "is statistically significant, indicating that the relationship between the independent variable and the dependent\n",
        "variable is unlikely to occur\n"
      ],
      "metadata": {
        "id": "v1LsumaTWiyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q4: What is the difference between a univariate and multivariate GLM\n",
        "Sol 4: In a univariate GLM, there is only one dependent variable  being analysed. The model focuses on examining the\n",
        "relationship between this single dependent variable. In contrast, a multivariate GLM involves analysing multiple\n",
        "dependent variables simultaneously.The model examines the relationship between these dependent variables and the\n",
        "independent variables."
      ],
      "metadata": {
        "id": "FWC0FdMgXwcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q7. What is the purpose of the design matrix in a GLM?\n",
        "\n",
        "Sol 7:The purpose of the design matrix in a GLM is:\n",
        "1. Encoding Independent Variables:\n",
        "The design matrix represents the independent variables in a structured manner. Each column of the matrix corresponds\n",
        "to a specific independent variable, and each row corresponds to a data point.\n",
        "2. Incorporating Nonlinear Relationships:\n",
        "The design matrix can include transformations or interactions of the original independent variables to capture nonlinear\n",
        "relationships between the predictors and the dependent variable.\n",
        "3. Handling Categorical Variables:\n",
        "The design matrix can handle categorical variables by using dummy coding . Dummy variables are binary variables\n",
        "representing the categories of the original variable.\n",
        "4. Estimating Coefficients:\n",
        "The design matrix allows the GLM to estimate the coefficients for each independent variable. By incorporating the design\n",
        "matrix into the GLM's estimation procedure estimating the magnitude and significance of the effects of each predictor.\n",
        "5. Making Predictions:\n",
        "The GLM can generate predictions for the dependent variable based on the values of the independent variables."
      ],
      "metadata": {
        "id": "9Qg6_tbGYVmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q11. What is regression analysis and what is its purpose?\n",
        "Sol 11:Regression analysis is a statistical method which shows the relationship between two or more variables.\n"
      ],
      "metadata": {
        "id": "YNhYMoiTafpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12.What is the difference between simple linear regression and multiple linear regression?\n",
        "Sol 12:Simple linear regression has only one x and one y variable. Multiple linear regression has one y and two or\n",
        "more x variables."
      ],
      "metadata": {
        "id": "oa9F7nyda3tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q13.How do you interpret the R-squared value in regression?\n",
        "Sol 13: An R-Squared value of 0 means that the model explains or predicts 0% of the relationship between the\n",
        "dependent and independent variables. A value of 1 indicates that the model predicts 100% of the relationship,\n",
        "and a value of 0.5 indicates that the model predicts 50%, and so on."
      ],
      "metadata": {
        "id": "6-TQJlcYbLfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q14.What is the difference between correlation and regression?\n",
        "Sol 14: Correlation measures the degree of a relationship between two independent variables . In contrast,\n",
        "regression is how one variable affects another."
      ],
      "metadata": {
        "id": "liZDvz7fbbaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q15.What is the difference between the coefficients and the intercept in regression?\n",
        "Sol 15:Coefficient is the slope of the line and intercept is the constant."
      ],
      "metadata": {
        "id": "bPCOiuwxbr5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q16. How do you handle outliers in regression analysis?\n",
        "Sol 16: 1.Removing outliers.\n",
        "\t      2.Replace with mean or median.\n",
        "\t      3.Quantile based flooring and capping.\n",
        "\t      4.Transformation with logarithm, square root, or reciprocal of the data."
      ],
      "metadata": {
        "id": "IYSLYqtpb2rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q17. What is the difference between ridge regression and ordinary least squares regression?\n",
        "Sol 17: The objective of OLS is to find the best-fit line that minimises the sum of squared residuals between\n",
        "the observed data points and the anticipated values from the linear model whereas Ridge Regression reduces\n",
        "the variance of the model and can improve its predictive performance."
      ],
      "metadata": {
        "id": "wCQcobhmcCvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q18. What is heteroscedasticity in regression and how does it affect the model?\n",
        "Sol 18: When residual does not follow any specific pattern that is heteroscedasticity in regression."
      ],
      "metadata": {
        "id": "L7nJEmFhcNet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q19. How do you handle multicollinearity in regression analysis?\n",
        "Sol 19: 1. Drop some of the correlated features.\n",
        "\t      2.Perform Principal components analysis.\n",
        "\t      3.Do some linear transformation e.g., add/subtract.\n"
      ],
      "metadata": {
        "id": "VsNcDx7TcU_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q20. What is polynomial regression and when is it used?\n",
        "Sol 20:Polynomial regression helps to identify the curvilinear relationship between independent and dependent variables ."
      ],
      "metadata": {
        "id": "cZKYsxPIcb7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q21. What is a loss function and what is its purpose in machine learning?\n",
        "Sol 21: The loss function is  the difference between the actual output and the predicted output from the model for\n",
        "the single training .It measures how good our prediction model does in terms of being able to predict the expected outcome.\n",
        "Then  we convert the learning problem into an optimization problem."
      ],
      "metadata": {
        "id": "OE1BIk-dcil6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q22. What is the difference between a convex and non-convex loss function?\n",
        "Sol 22: Convex loss has only one local optimum point. On the other hand, non convex problems have multiple optimum points."
      ],
      "metadata": {
        "id": "OLTdjq0ZcvNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q23. What is mean squared error (MSE) and how is it calculated?\n",
        "Sol 23: Mean Squared error is the average squared difference between the estimated values and the actual value.\n",
        "Mathematically, the mean squared erro is calculated as:\n",
        "Loss(y, ŷ) = (1/n) * ∑(y - ŷ)^2\n"
      ],
      "metadata": {
        "id": "AJu9ZvJ7c2KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q24. What is mean absolute error (MAE) and how is it calculated?\n",
        "Sol 24: Mean Absolute Error calculates the average difference between the calculated values and actual values.\n",
        "Mathematically, the mean absolute error is calculated as:\n",
        "Loss(y, ŷ) = (1/n) * ∑|y - ŷ|\n"
      ],
      "metadata": {
        "id": "BpW3GT-Yc-3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q25: What is log loss (cross-entropy loss) and how is it calculated?\n",
        "Sol 25:Log loss is commonly used for classification problems, where the goal is to classify instances\n",
        "into different classes. It quantifies the difference between the predicted probabilities and the true binary labels."
      ],
      "metadata": {
        "id": "X3kKueR1dFk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q28. What is Huber loss and how does it handle outliers?\n",
        "Sol 28: Huber loss is less sensitive to outliers in data than the squared error loss."
      ],
      "metadata": {
        "id": "DKqaWDkredmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q30. What is the difference between squared loss and absolute loss?\n",
        "Sol 30:Squared loss calculates the average of the squared differences between the predicted and true values.\n",
        "Absolute loss measures the average of the absolute differences between the predicted and true values."
      ],
      "metadata": {
        "id": "kk05F4m4fRX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q31. What is an optimizer and what is its purpose in machine learning?\n",
        "Sol 31:An optimizer is amethod used to adjust the parameters of a model in order to minimize the loss function.\n",
        "It determine the direction and magnitude of the parameter updates based on the gradients of the loss or objective function."
      ],
      "metadata": {
        "id": "Kx5e1mUhf1nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q32. What is Gradient Descent (GD) and how does it work?\n",
        "Sol 32:Gradient Descent is a optimization algorithm that iteratively adjusts the model's parameters in the direction\n",
        "opposite to the gradient of the loss function. It continuously takes small steps towards the minimum of the loss function\n",
        "until convergence is achieved."
      ],
      "metadata": {
        "id": "x0JkatC1gir7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q33. What are the different variations of Gradient Descent?\n",
        "Sol 33:The following are the variations of GD:\n",
        "        Batch Gradient Descent\n",
        "        Stochastic Gradient Descent\n",
        "        Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "xoTK0S_Fg9n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q34. What is the learning rate in GD and how do you choose an appropriate value?\n",
        "Sol 34: Learning rate is hyperparameter that determines the step size for parameter updates.\n",
        "        Some approaches for choosing appropriate value:\n",
        "          Grid Search\n",
        "          Learning Rate Schedules\n",
        "          Momentum\n",
        "          Learning Rate Decay"
      ],
      "metadata": {
        "id": "XZgCSpwyiO5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q35. How does GD handle local optima in optimization problems?\n",
        "Sol 35:Momentum is a technique that helps overcome local minima and accelerates convergence."
      ],
      "metadata": {
        "id": "wUyfV0Ysjv0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?\n",
        "Sol 35:Stochastic Gradient Descent updates the parameters using the gradients computed for a single training example at a time.\n",
        "In contras SGD continuously takes small steps towards the minimum of the loss function until convergence is achieved."
      ],
      "metadata": {
        "id": "nFQlP-n1kV8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q37.Explain the concept of batch size in GD and its impact on training?\n",
        "Sol 37: The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through\n",
        "        before the model's internal parameters are updated."
      ],
      "metadata": {
        "id": "Ms9WOwifoJAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q38. What is the role of momentum in optimization algorithms?\n",
        "Sol 38:Momentum is a technique that helps overcome local minima and accelerates convergence. It introduces a \"momentum\"\n",
        "term that accumulates the gradients over time. In addition to the learning rate, we need to tune the momentum hyperparameter.\n",
        "Higher values of momentum can smooth out the update trajectory and help navigate flat regions, while lower values\n",
        "allow for more stochasticity.\n"
      ],
      "metadata": {
        "id": "ViFYNvp6p_kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q39. What is the difference between batch GD, mini-batch GD, and SGD?\n",
        "Sol 39:Batch Gradient Descent computes the gradients using the entire training dataset in each iteration. It calculates\n",
        "the average gradient over all training examples and updates the parameters accordingly.\n",
        "Mini batch GD updates the parameters using a small random subset of training examples (mini-batch) at each iteration.\n",
        "Stochastic Gradient Descent updates the parameters using the gradients computed for a single training example at a time."
      ],
      "metadata": {
        "id": "W01se70hqaZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q41:What is regularization and why is it used in machine learning?\n",
        "Sol 41:Regularization is a technique used in machine learning to prevent overfitting and improve the generalization\n",
        "    ability of a model. It introduces additional constraints or penalties to the loss function, encouraging the model to\n",
        "    learn simpler patterns and avoid overly complex or noisy representations. Regularization helps strike a balance between\n",
        "    fitting the training data well and avoiding overfitting, thereby improving the model's performance on unseen data."
      ],
      "metadata": {
        "id": "UVUzGyZYrMe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q42. What is the difference between L1 and L2 regularization?\n",
        "Sol 42: L1 regularization adds a penalty term to the loss function proportional to the absolute values of the model's coefficients\n",
        "        in contrast L2 regularization adds a penalty term to the loss function proportional to the square of the model's coefficients."
      ],
      "metadata": {
        "id": "016HWyTLrsNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q43. Explain the concept of ridge regression and its role in regularization.\n",
        " Ridge regularization, adds a penalty term to the loss function that is proportional to the sum of the squared values of the\n",
        "model's coefficients. It encourages smaller magnitudes of all coefficients without forcing them to zero."
      ],
      "metadata": {
        "id": "5T2FYKkIr-BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q44.What is the difference between feature selection and regularization\n",
        "\n",
        "Sol 44: Regularization techniques promote sparsity in the model by driving some coefficients to exactly zero. Feature selectionrelevant\n",
        "or redundant features are automatically ignored by the model."
      ],
      "metadata": {
        "id": "7pfXzwBRsRyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLBTw4lLsR47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}